\documentclass[11pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[pdftex]{graphicx}
\usepackage{amsfonts,eucal,amsbsy,amsopn,amsmath}
\usepackage{url}
\usepackage[sort&compress]{natbib}
\usepackage{latexsym}
\usepackage{sectsty}
\usepackage[dvipsnames,usenames]{color}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{caption}
\usepackage{fancyhdr}
\usepackage{times}
\renewcommand{\captionfont}{\small}
\allsectionsfont{\normalsize}
\pagestyle{fancy}
\lhead{}
\chead{}
\rhead{}
\lfoot{}
\cfoot{\thepage~of~\pageref{lastpage}}
\rfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\usepackage{enumitem}
\setitemize{noitemsep,topsep=6pt,parsep=0pt,partopsep=0pt,leftmargin=1em}
\setenumerate{noitemsep,topsep=6pt,parsep=0pt,partopsep=0pt,leftmargin=1em}

\makeatletter
\renewcommand{\paragraph}{%
  \@startsection{paragraph}{4}%
  {\z@}{1.25ex \@plus 1ex \@minus .2ex}{-1em}%
  {\normalfont\normalsize\bfseries}%
}
\makeatother

\usepackage[compact]{titlesec}

%%%%%%%%%%%%%%%%%
\newcommand{\mc}{\mathcal}
\newcommand{\mb}{\mathbb}
\newcommand{\I}{\mathbb{I}}
%%%%%%%%%%%%%%%%%

\title{Team Interpretability and Community Modeling:  Final Report \\ CSE 481 N}
\author{Michael Zhang, Shobhit Hathi, and Yifan Xu}
\date{June 2019}

\begin{document}
\maketitle

\begin{abstract}
Write this last.  Include the key message of the document, distilled into one paragraph.  This is not a summary of what you did; itâ€™s a summary that helps a reader decide whether to keep reading.  For this report, it makes sense to include a statement that this is a capstone class project, to give some context.
\end{abstract}

\section{Introduction}
Deep classifiers can generally be decomposed into a feature extractor that distills a high-dimensional input into a low-dimensional representation, followed by a softmax layer that produces a multinomial distribution over the space of possible output classes from an instance's learned representation. Recent work from \citet{card.2019} proposed \textit{deep weighted averaging classifiers} (henceforth DWAC) as a alternative to the softmax layer in deep classifiers. DWAC makes predictions by computing a weighted sum over all training instances based on a learned metric of similarity. Although using DWAC still doesn't allow us to understand \textit{why} the model relates a pair of instances, we can observe \textit{what} the model is learning to relate together and \textit{how} it affects the model's predictions. In addition to this heightened transarency from DWAC, the authors of \citet{card.2019} also find that this transparency can be directly utilized in improving model robustness under the framework of \textit{conformal methods} (reviewed in section KAKAKA).

A major drawback of DWAC is that predictions require comparisons against the entire training set. \citet{card.2019} proposes an approximate objective that makes training tractable, but even with these changes the model's performance, with regards to both speed and accuracy, suffers on large datasets. Motivated by these drawbacks, we propose an alternative to DWAC that utilizes a small set of \textit{prototypes} that the model computes a weighted average over to make a prediction. Functionally, theses prototypes replace the role of the training set in the original DWAC model at both training and test time. We find that our new \textit{prototyped deep weighted averaging classifier} model (henceforth ProtoDWAC) maintains or inproves on many of the same desireable characteristics as the original DWAC model (i.e. accuracy, credibility, robustness, transparency), while making training and testing signifigantly faster, more stable, and better suited for larger datasets.

In the sections below we review conformal methods (SECTION) which we use to evaluate and quantify a model's robustness and calibration. We then review the original DWAC model () before introducing
our proposed ProtoDWAC model (). After the models are introduced, we move on to our model's empirical performance, comparing the effect of our proposed model on accuracy and claibration (), robustness (), and transparency/interpretability ().

\section{Background}
\subsection{Conformal Methods}
\textit{Conformal Methods} refer to a broad range of methods that can be applied to any existing classification or regression system to provide theoretical guarantees on error rates. For our purposes we offer a condensed description of conformal methods that is tailored to our sepecific setting of probablistic models for classification.\footnote{For a more general overview, see \citet{card.2019}, (KAKA), (KAKA), or (KAKA).} Conformal methods methods rely on a scalar metric of \textit{nonconformity}, $\eta$, that can be computed on our trained model, $\mc{M}$, for each test instance, $x$, and output class, $k$, pair, i.e.
\begin{equation}
\eta(x, k) = A(\mc{M}, (x, k))
\end{equation}

This measure of nonconformity intuitively correlates to a measure of how \textit{atypical} a test instance is of the given class. These measures of nonconformity can be defined many ways, but for probablistic classification models, a natural measure of nonconformity is the inverse (multiplicative or additive) of the probabilty of a test instance being assigned the given class, i.e.
\begin{equation} \label{inv.prob}
\eta(x, k) = -P_{\mc{M}}(y = k | x)
\end{equation}

Conformal methods work by comparing the nonconformity score of each possible prediction against those of each example inside a calibration set, $(x, y) \in \mc{C}$, that has been held out from training. We compute a $p$-value for each possible output label equal to the proportion of calibration instances with a higher nonconformity score. More precisely, our $p$-values for a test instance
and hypothesized label pairing is computed as such:
\begin{equation}
  p(x, k) = \frac{\sum_{(x_c, y_c) \in \mc{C}} \I(\eta(x_c, y_c) \geq \eta(x, k))}{|\mc{C}|}
\end{equation}

Under this framework, we can provide our classifiers a desired error rate, $\epsilon$, and allow our model to predict a possibly-empty set of labels $\{k \in \mc{Y} : p(x, k) > \epsilon\}$ for each test instance with gurantees that the predicted label set will contain the true label with error rate $\epsilon$ with high probability.

The authors of \citet{saunders.1999} proposed two metrics for evalutaing classificaiton models using conformal methods:
\begin{itemize}
\item\textbf{Confidence} is equal to the largest $1 - \epsilon$ such that the predicted label set
  contains exactly one label. This measure corresponds to the probability, according to the model, that the predicted label is correct.
\item \textbf{Credibility} is equal to the smallest $1 - \epsilon$ such that the predicted label set is empty. This measure corresponds to the probability, acording to the model, that none of the possible labels are correct.
\end{itemize}

In settings where predicting a set of labels doesn't make sense, using conformal methods can allow us to yield a single label as well as an associated confidence and credibility score for the prediction.

\subsection{Deep Weighted Averaging Classifiers}
Traditional softmax-based deep classifiers produce output probabilitys on classes by the following:
\begin{equation}
  P(y = k | x) = \frac{\exp([h]_k)}{\sum_{i=1}^j([h]_i)}
\end{equation}
where $h = W f(x) + b$. Here we make explicit the separation between the feature extractor portion of the deep model, $f(x)$, which yields a low-dimensional representation of the input and the softmax layer.

In contrast, DWAC models may retain the same feature extractor $f(x)$, however replace the affine transformation and softmax with the following:
\begin{equation} \label{dwac:probs}
  P(y = k | x) = \frac{\sum_{(x_t, y_t) \in \mc{T}} \I(y_t = k) w(f(x_t), f(x))}{\sum_{(x_t, y_t) \in \mc{T}} w(f(x_t), f(x))}
\end{equation}
where $w(a, a')$ is a function of similarity between the embeddings $a$ and $a'$. In \citet{card.2019} and for the rest of this work, we will define $w$ to be the gaussian kernel with standard deviation $\sigma = \frac{1}{2}$:
\begin{equation}
  w(a, a') = \exp(- \| a - a' \|_2^2)
\end{equation}

Because comparing each example against the entire training set isn't tractable during training, DWAC leans on using the following approximation, replacing the training set with all other
examples in the same minibatch, $\mc{B}$:
\begin{equation} \label{dwac:approx}
  P(y = k | x) \approx \widehat{P}(y = k | x) = \frac{\sum_{(x_b, y_b) \in \mc{B}, x_b \neq x} \I(y_b = k) w(f(x_b), f(x))}{\sum_{(x_b, y_b) \in \mc{B}, x_b \neq x} w(f(x_b), f(x))}
\end{equation}

\section{Prototyped Deep Weighted Averaging Classifiers}
When using ProtoDWAC, we replace the weighted sum against the training set with a set of prototypes, $\mc{P}$, which are each associated with a given label. In practice, we associate a
constant number of prototypes with each output class. Our model now assigns probabilities according to the following:
\begin{equation} \label{proto:probs}
  P(y = k | x) = \frac{\sum_{(x_p, y_p) \in \mc{P}} \I(y_p = k) w(f(x_p), f(x))}{\sum_{(x_p, y_p) \in \mc{P}} w(f(x_p), f(x))}
\end{equation}

\subsection{Training and Time Complexity}
In ProtoDWAC, we do not need to make the training time approximations as in equation~\ref{dwac:approx} becuase the set of prototypes is vastly smaller than the training set. Additionally, ProtoDWAC avoids issues posed to the DWAC model with regards to class imbalences in the training set as in addition

At test time, predicting on a single instance takes $\mc{O}(|\mc{T}|z)$ where $z$ is the dimensions of the hidden representation. In contrast softmax models and ProtoDWAC (for a constant number of prototypes per class) take $\mc{O}(zk)$ where $k$ is the number of output classes. Using prototypes allows us to remove the linear scaling factor with respect to the size of the training set: the primary bottleneck of the DWAC model.

\subsection{Measures of Nonconformity}
As noted in \cite{card.2019}, DWAC models have a natural measure of nonconformity that's different than the traditional inverse probability transformation in equation.~\ref{inv.prob}. Although less \textit{exact} than the inverse probability, the inverse of the numerator from equation~\ref{dwac:probs} also grows inversely to the probability. Additionally, using the inverse numerator as a measure of non-conformity also has an intuitive interpretation as it correlates with the summed embedded distances from all instances of the same class in the training set. For ProtoDWAC, we also experiment with using the analog of this as a measure of nonconformity: the inverse of equation~\ref{proto:probs}.



\section{Experiments}
\subsection{Standard Experiments on IMDB and StackOverflow}
\begin{itemize}
  \item number of output classes
  \item Introduce the feature extractor model \citet{mullenbach.2018}
  \item Softmax Baseline, DWAC, ProtoDWAC (with variable number of prototypes/class)
\end{itemize}

\subsection{Out-of-domain data experiments and label ablations}
\begin{itemize}
  \item Experiment with ablating multiple labels at once from StackOverflow data
  \item Experiment with OOD data detection on IMDB. Data taken from ???
\end{itemize}

\section{Results}
\subsection{Accuracy and Calibration}
\subsection{Confidence and Credibility}
\subsection{Interpretability and Visualizations}
\subsection{Out-of-domain data experiments and label ablations}

\section{Related Work}

\section{Conclusion}

\newpage
\bibliographystyle{plainnat}
\bibliography{refs}\label{lastpage}

\end{document}
